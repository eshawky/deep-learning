{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import os"
      ],
      "metadata": {
        "id": "rAhRv0D7J-v9"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "u6QcKWX7WA-R"
      },
      "outputs": [],
      "source": [
        "tensor_h = tf.random.normal([4,100,100,3])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#tensor_h[0,:,:,:]"
      ],
      "metadata": {
        "id": "DhvSDFs0WM2-"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#tensor_h[::2,...]"
      ],
      "metadata": {
        "id": "lTAqBfs6WTAI"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tensor_h[::-1].shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ANPAjWvdWTn0",
        "outputId": "3278b70a-a220-49b1-bf27-2b44f8ec76e1"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([4, 100, 100, 3])"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tensor_h[:4].shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sJ07BruBWTrb",
        "outputId": "404ee1bc-85f7-4bcc-8e14-d975f958347d"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([4, 100, 100, 3])"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tensor_h[3].shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9FU_RjGfWTuI",
        "outputId": "8b5fc147-9c72-4de5-814f-4d708a3e56f7"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([100, 100, 3])"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tensor_h[0][19][39][1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O57jE9JyWTxe",
        "outputId": "d5d63b49-600c-469a-ff44-ffe18e5a0afc"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(), dtype=float32, numpy=-0.56566644>"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "indices = [0,1,3]\n",
        "tf.gather(tensor_h,axis=0,indices=indices).shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cmsxsy7KWT0p",
        "outputId": "822e9632-d285-4b6b-eab9-0debb995f3d8"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([3, 100, 100, 3])"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "indices = [[0,1,1,0],[1,2,2,0]]\n",
        "indices[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HzZE-QNZWT3F",
        "outputId": "974175be-40bc-48f2-eeef-e53223721c47"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0, 1, 1, 0]"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tf.gather_nd(tensor_h,indices=indices)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F-g7PFFXWT6C",
        "outputId": "ae131302-1f77-446d-f30f-9bb41d1ddbd9"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(2,), dtype=float32, numpy=array([-0.55698514, -0.4514959 ], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Generate a 100 x 100 x 3 tensor to represent a 100 x 100 three-channel color image.\n",
        "expand_sample_1 = tf.random.normal([100,100,3], seed=1)\n",
        "print(\"size of the original data:\",expand_sample_1.shape)\n",
        "print(\"add a dimension before the first dimension (axis = 0): \" ,tf.expand_dims(expand_sample_1, axis=0).shape)\n",
        "print(\"add a dimension before the second dimension (axis = 1): \",tf.expand_dims(expand_sample_1, axis=1).shape)\n",
        "print(\"add a dimension before the second dimension (axis = 1): \",tf.expand_dims(expand_sample_1, axis=2).shape)\n",
        "print(\"add a dimension after the last dimension (axis = –1): \"  ,tf.expand_dims(expand_sample_1, axis=3).shape)\n",
        "print(\"add a dimension before the second dimension (axis = 1): \",tf.expand_dims(expand_sample_1,axis=-1).shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R0Z-S496cMdi",
        "outputId": "3a1252bf-26bf-47b5-de98-7840a7d9c127"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "size of the original data: (100, 100, 3)\n",
            "add a dimension before the first dimension (axis = 0):  (1, 100, 100, 3)\n",
            "add a dimension before the second dimension (axis = 1):  (100, 1, 100, 3)\n",
            "add a dimension before the second dimension (axis = 1):  (100, 100, 1, 3)\n",
            "add a dimension after the last dimension (axis = –1):  (100, 100, 3, 1)\n",
            "add a dimension before the second dimension (axis = 1):  (100, 100, 3, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Generate a 100 x 100 x 3 tensor to represent a 100 x 100 three-channel color image.\n",
        "squeeze_sample_1 = tf.random.normal([1,2,2,3])\n",
        "print(\"size of the original data:\",squeeze_sample_1.shape)\n",
        "\n",
        "squeezed_sample_1 = tf.squeeze(squeeze_sample_1)\n",
        "print(\"data size after dimension squeezing:\",squeezed_sample_1.shape)\n",
        "squeezed_sample_1 = tf.squeeze(squeezed_sample_1)\n",
        "print(\"data size after dimension squeezing:\",squeezed_sample_1.shape)\n",
        "\n",
        "squeezed_sample_1 = tf.squeeze(squeezed_sample_1)\n",
        "print(\"data size after dimension squeezing:\",squeezed_sample_1.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oxLJr6G_cMpH",
        "outputId": "aa115c1f-ddca-456e-c8c5-cec91ea0ad51"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "size of the original data: (1, 2, 2, 3)\n",
            "data size after dimension squeezing: (2, 2, 3)\n",
            "data size after dimension squeezing: (2, 2, 3)\n",
            "data size after dimension squeezing: (2, 2, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a = tf.constant([[ 0, 0, 0],\n",
        "                 [10,10,10],\n",
        "                 [20,20,20],\n",
        "                 [30,30,30]])\n",
        "b = tf.constant([1,2,3])\n",
        "\n",
        "print(\"A: \", a    )\n",
        "print(\"B: \", b    )\n",
        "print(\"A,b\", a + b)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LefsEG42cMvI",
        "outputId": "01b4cc58-5171-458b-bf75-38ee96003b10"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "A:  tf.Tensor(\n",
            "[[ 0  0  0]\n",
            " [10 10 10]\n",
            " [20 20 20]\n",
            " [30 30 30]], shape=(4, 3), dtype=int32)\n",
            "B:  tf.Tensor([1 2 3], shape=(3,), dtype=int32)\n",
            "A,b tf.Tensor(\n",
            "[[ 1  2  3]\n",
            " [11 12 13]\n",
            " [21 22 23]\n",
            " [31 32 33]], shape=(4, 3), dtype=int32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a = tf.constant([[3, 5], [4, 8]])\n",
        "b = tf.constant([[1, 6], [2, 9]])\n",
        "print(tf.add(a, b))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "izXYoTR5cMxm",
        "outputId": "c2295ce8-f31c-4258-9fb6-d77d697bc456"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[[ 4 11]\n",
            " [ 6 17]], shape=(2, 2), dtype=int32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "reduce_sample_1 = tf.constant([1,2,3,4,5,6],shape=[2,3])\n",
        "print(\"original data\",reduce_sample_1.numpy())\n",
        "print(\"calculate the sum of all elements in the tensor (axis = None):     \",tf.reduce_sum(reduce_sample_1,axis=None).numpy())\n",
        "print(\"calculate the sum of elements in each column by column (axis = 0): \",tf.reduce_sum(reduce_sample_1,axis=0).numpy())\n",
        "print(\"calculate the sum of elements in each column by row (axis = 1):    \",tf.reduce_sum(reduce_sample_1,axis=1).numpy())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BZSMpr37cM0E",
        "outputId": "c5bf46c6-de11-42af-b66c-f2ec9131f6f2"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "original data [[1 2 3]\n",
            " [4 5 6]]\n",
            "calculate the sum of all elements in the tensor (axis = None):      21\n",
            "calculate the sum of elements in each column by column (axis = 0):  [5 7 9]\n",
            "calculate the sum of elements in each column by row (axis = 1):     [ 6 15]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "stack_sample_1 = tf.random.normal([100,100,3])\n",
        "stack_sample_2 = tf.random.normal([100,100,3])\n",
        "print(\"sizes of the original data: \",stack_sample_1.shape, stack_sample_2.shape)\n",
        "\n",
        "#Dimensions increase after the concatenation. If axis is set to 0, a dimension is added before the first dimension.\n",
        "stacked_sample_1 = tf.stack([stack_sample_1, stack_sample_2],axis=0)\n",
        "print(\"size of the concatenated data:\",stacked_sample_1.shape)\n",
        "\n",
        "#Split data based on the first dimension and output the split data in a list.\n",
        "result = tf.unstack(stacked_sample_1,axis=0)\n",
        "print (result[0].shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CI46eBU4cM3L",
        "outputId": "bb3d858d-1675-43a0-a3ea-bb534cd67256"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sizes of the original data:  (100, 100, 3) (100, 100, 3)\n",
            "size of the concatenated data: (2, 100, 100, 3)\n",
            "(100, 100, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "split_sample_1 = tf.random.normal([10,100,100,3])\n",
        "print(\"size of the original data:\",split_sample_1.shape)\n",
        "\n",
        "splited_sample_1 = tf.split(split_sample_1, num_or_size_splits=5,axis=1)\n",
        "print(\"size of the split data when m_or_size_splits is set to 10: \",np.shape(splited_sample_1))\n",
        "\n",
        "splited_sample_2 = tf.split(split_sample_1, num_or_size_splits=[3,5,2],axis=0)\n",
        "print(\"sizes of the split data when num_or_size_splits is set to [3,5,2]:\", np.shape(splited_sample_2[0]), np.shape(splited_sample_2[1]), np.shape(splited_sample_2[2]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tA0pouTPcM6g",
        "outputId": "f6dc28a8-ed16-4e34-82a8-ac20bc5f9813"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "size of the original data: (10, 100, 100, 3)\n",
            "size of the split data when m_or_size_splits is set to 10:  (5, 10, 20, 100, 3)\n",
            "sizes of the split data when num_or_size_splits is set to [3,5,2]: (3, 100, 100, 3) (5, 100, 100, 3) (2, 100, 100, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sort_sample_1 = tf.random.shuffle(tf.range(10))\n",
        "print(\"input tensor:\",sort_sample_1.numpy())\n",
        "\n",
        "sorted_sample_1 = tf.sort(sort_sample_1, direction=\"ASCENDING\")\n",
        "print(\"tensor sorted in ascending order:\",sorted_sample_1.numpy())\n",
        "\n",
        "sorted_sample_2 = tf.argsort(sort_sample_1,direction=\"ASCENDING\")\n",
        "print(\"indexes of elements in ascending order:\",sorted_sample_2.numpy())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vb7ByY_1cM-U",
        "outputId": "d536916f-3db6-44f2-cbed-096d00d37d33"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "input tensor: [4 0 6 1 3 8 7 9 5 2]\n",
            "tensor sorted in ascending order: [0 1 2 3 4 5 6 7 8 9]\n",
            "indexes of elements in ascending order: [1 3 9 4 0 8 2 6 5 7]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sort_sample_1 = tf.random.shuffle(tf.range(10))\n",
        "print(\"input tensor:\",sort_sample_1.numpy())\n",
        "\n",
        "values, index = tf.nn.top_k(sort_sample_1,5)\n",
        "print(\"first five values in ascending order:\", values.numpy())\n",
        "print(\"indexes of the first five values in ascending order:\", index.numpy())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jc0EZ9HvcNBB",
        "outputId": "d18d9d52-f091-4d2b-fcc0-d93ac0bc0af7"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "input tensor: [1 0 9 7 2 5 4 6 8 3]\n",
            "first five values in ascending order: [9 8 7 6 5]\n",
            "indexes of the first five values in ascending order: [2 8 3 7 5]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = tf.ones((2, 2), dtype=tf.dtypes.float32)\n",
        "y = tf.constant([[1, 2], [3, 4]], dtype=tf.dtypes.float32)\n",
        "z = tf.matmul(x, y)\n",
        "print(z)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LhfpL-_xcNEs",
        "outputId": "79935856-366e-48f0-b260-38464845485e"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[[4. 6.]\n",
            " [4. 6.]], shape=(2, 2), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Graph Mode we must use with tf.Session as session, session.run()\n",
        "# #Use the syntax of TensorFlow 1.x in TensorFlow 2.x. You can install the v1 compatibility package in TensorFlow 2.0 to inherit the TensorFlow 1.x code and disable the eager execution mode.\n",
        "# import tensorflow.compat.v1 as tf\n",
        "# tf.enable_eager_execution()\n",
        "\n",
        "# #Create a graph and define it as a computational graph.\n",
        "# x = tf.ones((2, 2), dtype=tf.dtypes.float32)\n",
        "# y = tf.constant([[1, 2], [3, 4]], dtype=tf.dtypes.float32)\n",
        "# z = tf.matmul(x, y)\n",
        "# print (z)\n",
        "\n",
        "# #Enable the drawing function, and perform the multiplication operation to obtain data.\n",
        "# with tf.Session() as sess:\n",
        "#       print(\"z values are\\n \", sess.run(z))\n"
      ],
      "metadata": {
        "id": "dSin_JXfcNIj"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Eager excution for conditions (control flow)\n",
        "thre_1 = tf.random.uniform([], 0, 1)\n",
        "x      = tf.reshape(tf.range(0, 4), [2, 2])\n",
        "print(thre_1)\n",
        "\n",
        "if thre_1.numpy() > 0.5:\n",
        "  y = tf.matmul(x, x)\n",
        "else:\n",
        "  y = tf.add(x, x)\n",
        "\n",
        "print (y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0nECMqdMXXpX",
        "outputId": "f7f3554a-24d4-4060-8168-4f15dea7c20c"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(0.6772187, shape=(), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[ 2  3]\n",
            " [ 6 11]], shape=(2, 2), dtype=int32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Autograph\n",
        "@tf.function\n",
        "def simple_nn_layer(w,x,b):\n",
        "  print(b)\n",
        "  return tf.nn.relu(tf.matmul(w, x)+b)\n",
        "\n",
        "w = tf.random.uniform((3, 3))\n",
        "x = tf.random.uniform((3, 3))\n",
        "b = tf.constant(0.5, dtype='float32')\n",
        "\n",
        "simple_nn_layer(w,x,b).shape\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3VTqp1lFaqrj",
        "outputId": "bec69359-1aec-462f-b338-70e6fd355934"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tensor(\"b:0\", shape=(), dtype=float32)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([3, 3])"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Compare the perfomance in time between graph mode, and eager excution mode\n",
        "#Use the timeit module to measure the execution time of a small code segment.\n",
        "import timeit\n",
        "\n",
        "image = tf.zeros([100, 200, 200, 3])\n",
        "\n",
        "#Create a convolutional layer.\n",
        "CNN_cell = tf.keras.layers.Conv2D(filters=100,kernel_size=2,strides=(1,1))\n",
        "\n",
        "#Use @tf.function to convert the operation into a graph.\n",
        "@tf.function\n",
        "def CNN_fn(image):\n",
        "  return CNN_cell(image)\n",
        "\n",
        "#Compare the execution time of the two modes.\n",
        "CNN_cell(image)\n",
        "cell_fun = CNN_fn(image)\n",
        "\n",
        "#Call timeit.timeit to measure the time required for executing the code 10 times.\n",
        "print(\"time required for performing the computation of one convolutional neural network (CNN) layer in eager execution mode:\\n\", \n",
        "      timeit.timeit(lambda: CNN_cell(image), number=10))\n",
        "\n",
        "print(\"time required for performing the computation of one CNN layer in graph mode:\\n\", \n",
        "      timeit.timeit(lambda: CNN_fn(image), number=10))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gyK4kSgKb-cK",
        "outputId": "69f78f2a-1b12-4e1d-94da-021ededba99e"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time required for performing the computation of one convolutional neural network (CNN) layer in eager execution mode:\n",
            " 10.741339390999201\n",
            "time required for performing the computation of one CNN layer in graph mode:\n",
            " 7.633622794000985\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_x = np.random.random((1000, 36))\n",
        "train_y = np.random.random((1000, 10))\n",
        "val_x   = np.random.random((200, 36))\n",
        "val_y   = np.random.random((200, 10))\n",
        "model.fit(train_x, train_y, epochs=10, batch_size=100, validation_data=(val_x, val_y))\n",
        "\n",
        "#Use tf.data module\n",
        "dataset     = tf.data.Dataset.from_tensor_slices((train_x, train_y))\n",
        "dataset     = dataset.batch(32)\n",
        "dataset     = dataset.repeat()\n",
        "\n",
        "val_dataset = tf.data.Dataset.from_tensor_slices((val_x, val_y))\n",
        "val_dataset = val_dataset.batch(32)\n",
        "val_dataset = val_dataset.repeat()\n",
        "\n",
        "model.fit(dataset, epochs=10, steps_per_epoch=30,validation_data=val_dataset, validation_steps=3)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "__efhQJwRf0x",
        "outputId": "bf5703b0-928e-4fb7-9839-5c924929db92"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "10/10 [==============================] - 0s 18ms/step - loss: 12.9495 - categorical_accuracy: 0.1040 - val_loss: 13.1429 - val_categorical_accuracy: 0.0950\n",
            "Epoch 2/10\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 12.9444 - categorical_accuracy: 0.1020 - val_loss: 13.1405 - val_categorical_accuracy: 0.1050\n",
            "Epoch 3/10\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 12.9427 - categorical_accuracy: 0.1020 - val_loss: 13.1400 - val_categorical_accuracy: 0.1050\n",
            "Epoch 4/10\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 12.9417 - categorical_accuracy: 0.1020 - val_loss: 13.1395 - val_categorical_accuracy: 0.1100\n",
            "Epoch 5/10\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 12.9418 - categorical_accuracy: 0.1030 - val_loss: 13.1409 - val_categorical_accuracy: 0.1100\n",
            "Epoch 6/10\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 12.9434 - categorical_accuracy: 0.1030 - val_loss: 13.1428 - val_categorical_accuracy: 0.1100\n",
            "Epoch 7/10\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 12.9446 - categorical_accuracy: 0.1040 - val_loss: 13.1441 - val_categorical_accuracy: 0.1050\n",
            "Epoch 8/10\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 12.9452 - categorical_accuracy: 0.1030 - val_loss: 13.1447 - val_categorical_accuracy: 0.1100\n",
            "Epoch 9/10\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 12.9461 - categorical_accuracy: 0.1040 - val_loss: 13.1457 - val_categorical_accuracy: 0.1050\n",
            "Epoch 10/10\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 12.9469 - categorical_accuracy: 0.1050 - val_loss: 13.1466 - val_categorical_accuracy: 0.1050\n",
            "Epoch 1/10\n",
            "30/30 [==============================] - 0s 5ms/step - loss: 12.9397 - categorical_accuracy: 0.1083 - val_loss: 13.1647 - val_categorical_accuracy: 0.1146\n",
            "Epoch 2/10\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 12.9455 - categorical_accuracy: 0.1090 - val_loss: 13.1610 - val_categorical_accuracy: 0.1146\n",
            "Epoch 3/10\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 12.9446 - categorical_accuracy: 0.1058 - val_loss: 13.1575 - val_categorical_accuracy: 0.1146\n",
            "Epoch 4/10\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 12.9568 - categorical_accuracy: 0.1079 - val_loss: 13.1547 - val_categorical_accuracy: 0.1146\n",
            "Epoch 5/10\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 12.9300 - categorical_accuracy: 0.1079 - val_loss: 13.1532 - val_categorical_accuracy: 0.1042\n",
            "Epoch 6/10\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 12.9273 - categorical_accuracy: 0.1036 - val_loss: 13.1520 - val_categorical_accuracy: 0.1042\n",
            "Epoch 7/10\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 12.9288 - categorical_accuracy: 0.1111 - val_loss: 13.1514 - val_categorical_accuracy: 0.1042\n",
            "Epoch 8/10\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 12.9294 - categorical_accuracy: 0.1068 - val_loss: 13.1502 - val_categorical_accuracy: 0.1042\n",
            "Epoch 9/10\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 12.9291 - categorical_accuracy: 0.1047 - val_loss: 13.1489 - val_categorical_accuracy: 0.0938\n",
            "Epoch 10/10\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 12.9473 - categorical_accuracy: 0.1058 - val_loss: 13.1477 - val_categorical_accuracy: 0.0938\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f255ffc5ad0>"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Set hyperparameters.\n",
        "Epochs = 10\n",
        "\n",
        "#Define a function for dynamically setting the learning rate.\n",
        "def lr_Scheduler(epoch):\n",
        "  \n",
        "  if epoch > 0.9 * Epochs:\n",
        "    lr = 0.0001\n",
        "  elif epoch > 0.5 * Epochs:\n",
        "    lr = 0.001\n",
        "  elif epoch > 0.25 * Epochs:\n",
        "    lr = 0.01\n",
        "  else:\n",
        "    lr = 0.1\n",
        "  \n",
        "  print(lr)\n",
        "  return lr\n"
      ],
      "metadata": {
        "id": "MFJp0mmJKqb1"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "callbacks = [\n",
        "                  #Early stopping:\n",
        "                  tf.keras.callbacks.EarlyStopping(\n",
        "                                                    #Metric for determining whether the model performance has no further improvement\n",
        "                                                    monitor='val_loss',\n",
        "                                                    #Threshold for determining whether the model performance has no further improvement\n",
        "                                                    min_delta=1e-2,\n",
        "                                                    #Number of epochs in which the model performance has no further improvement\n",
        "                                                    patience=2),\n",
        "\n",
        "                  #Periodically save models.\n",
        "                  tf.keras.callbacks.ModelCheckpoint(\n",
        "                                                      #Model path\n",
        "                                                      filepath='testmodel_{epoch}.h5',\n",
        "                                                      #Whether to save the optimal model.\n",
        "                                                      save_best_only=True,\n",
        "                                                      #Monitored metric\n",
        "                                                      monitor='val_loss'),\n",
        "\n",
        "                  #Dynamically change the learning rate.\n",
        "                  tf.keras.callbacks.LearningRateScheduler(lr_Scheduler),\n",
        "\n",
        "                  #Use TensorBoard.\n",
        "                  tf.keras.callbacks.TensorBoard(log_dir='./logs')\n",
        "              ]\n"
      ],
      "metadata": {
        "id": "LxqyUcMwK1sY"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = tf.keras.Sequential()\n",
        "model.add(tf.keras.layers.Dense(10, activation='softmax'))\n",
        "\n",
        "#Determine the optimizer (optimizer), loss function (loss), and model evaluation method (metrics).\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(0.001), loss  = tf.keras.losses.categorical_crossentropy, metrics=[tf.keras.metrics.categorical_accuracy])\n",
        "\n",
        "train_x = np.random.random((1000, 36))\n",
        "train_y = np.random.random((1000, 10))\n",
        "val_x   = np.random.random((200, 36))\n",
        "val_y   = np.random.random((200, 10))\n",
        "\n",
        "history = model.fit(train_x, train_y, batch_size=16, epochs=1, callbacks=callbacks, validation_data=(val_x, val_y))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aRpdjbN-LQuW",
        "outputId": "615786fc-622f-4074-f84b-42fe90eb051f"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.1\n",
            "63/63 [==============================] - 1s 4ms/step - loss: 12.4715 - categorical_accuracy: 0.1080 - val_loss: 12.4679 - val_categorical_accuracy: 0.0950 - lr: 0.1000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# create the file\n",
        "if not os.path.exists('./model/'):\n",
        "  os.mkdir('./model/')\n",
        "\n",
        "#Save models.\n",
        "model_name = './model/my_saved_model.h5'\n",
        "model.save(model_name)\n",
        "\n",
        "#Import models.\n",
        "new_model      = tf.keras.models.load_model(model_name)\n",
        "new_prediction = new_model.predict(val_x)\n",
        "\n",
        "#model.save_weights('./model/model_weights')\n",
        "model.save_weights('./model/model_weights.h5')\n",
        "\n",
        "#Load the weights.\n",
        "#model.load_weights('./model/model_weights')\n",
        "model.load_weights('./model/model_weights.h5')\n"
      ],
      "metadata": {
        "id": "tO6EuTL7SwC0"
      },
      "execution_count": 29,
      "outputs": []
    }
  ]
}